{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Three \n",
    "\n",
    "The primary description of this coursework is available on the CM20252 Moodle page. This is the Jupyter notebook you must complete and submit to receive marks. This notebook adds additional detail to the coursework specification but does not repeat the information that has already been provided there. \n",
    "\n",
    "You must follow all instructions given in this notebook precisely.\n",
    "\n",
    "Restart the kernel and run all cells before submitting the notebook. This will guarantee that we will be able to run your code for testing. Remember to save your work regularly.\n",
    "\n",
    "__You will develop players for Connect-Three on a grid that is 5 columns wide and 3 rows high. An example is shown below showing a win for Player Red.__\n",
    "\n",
    "<img src=\"images/connect3.png\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "For your reference, below is a visual depiction of the agent-environment interface in reinforcement learning. The interaction of the agent with its environments starts at decision stage $t=0$ with the observation of the current state $s_0$. (Notice that there is no reward at this initial stage.) The agent then chooses an action to execute at decision stage $t=1$. The environment responds by changing its state to $s_1$ and returning the numerical reward signal $r_1$. \n",
    "\n",
    "<img src=\"images/agent-environment.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "Below, we provide some code that will be useful for implementing parts of this interface. You are not obligated to use this code; please feel free to develop your own code from scratch. \n",
    "\n",
    "### Code details\n",
    "\n",
    "We provide a `Connect` class that you can use to simulate Connect-Three games. The following cells in this section will walk you through the basic usage of this class by playing a couple of games.\n",
    "\n",
    "We import the `connect` module and create a Connect-Three environment called `env`. The constructor method has one argument called `verbose`. If `verbose=True`, the `Connect` object will regularly print the progress of the game. This is useful for getting to know the provided code, debugging your code, or if you just want to play around. You will want to set `verbose=False` when you run hundreds of episodes to complete the marked exercises.\n",
    "\n",
    "This `Connect` environment uses the strings `'o'` and `'x'` instead of different disk colors in order to distinguish between the two players. We can specify who should start the game using the `starting_player` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game has been reset.\n",
      "[[' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "import Myconnect\n",
    "env = Myconnect.Connect(starting_player='x', verbose=True)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can interact with the environment using the `act()` method. This method takes an `action` (an integer) as input and computes the response of the environment. An action is defined as the column index that a disk is dropped into. The `act()` method returns the `reward` for player `'o'` and a boolean, indicating whether the game is over (`True`) or not (`False`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' 'x' ' ' ' ']]\n",
      "reward = 0\n",
      "game_over = False\n"
     ]
    }
   ],
   "source": [
    "reward, game_over = env.act(action=2)\n",
    "print(\"reward =\", reward)\n",
    "print(\"game_over =\", game_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we set `verbose=True` when we created our environment, the grid is printed each time we call the `act()` method. You probably might want to set `verbose=False` when you run Q-learning for thousands of episodes. \n",
    "\n",
    "As expected, the `reward` is 0 and no one has won the game yet (`game_over` is `False`). Let us drop another disk into the same column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' 'o' ' ' ' ']\n",
      " [' ' ' ' 'x' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "env.change_turn()\n",
    "reward, game_over = env.act(action=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the `Connect` environment automatically switches the\n",
    "\n",
    "The `grid` is stored as a two-dimensional `numpy` array in the `Connect` class and you can easily access it by calling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' 'x' ' ' ' ']\n",
      " [' ' ' ' 'o' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "current_grid = env.grid\n",
    "print(current_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the grid now appears to be \"upside down\" because `numpy` arrays are printed from \"top to bottom\".\n",
    "We can also print it the way it is printed by the Connect class by calling..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' 'o' ' ' ' ']\n",
      " [' ' ' ' 'x' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "print(current_grid[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make another move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' 'x' ' ' ' ']\n",
      " [' ' ' ' 'o' ' ' ' ']\n",
      " [' ' ' ' 'x' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "env.change_turn()\n",
    "reward, game_over = env.act(action=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to put another disk in the same column with `act(action=2)`. The environment will throw an error because that column is already filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-08cd2c81a094>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This cell should throw an IndexError!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mH:\\programming\\python\\Coursework+2+Materials-201903251\\ai4_connect_three\\connect.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \"\"\"\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lowest_free_row_per_column\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactive_player\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lowest_free_row_per_column\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# You can ignore this; internal use only.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lowest_free_row_per_column\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_rows\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "# This cell should throw an IndexError!\n",
    "env.change_turn()\n",
    "env.act(action=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `.available_actions` of the `Connect` class contains a `numpy` array of all not yet filled columns. This variable should help you to avoid errors like the one we have just encountered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(env.available_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that column index '2' is missing because this column is already filled.\n",
    "\n",
    "Let's keep on playing until some player wins..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[' ' ' ' 'x' ' ' ' ']\n",
      " [' ' ' ' 'o' ' ' ' ']\n",
      " [' ' ' ' 'x' 'x' ' ']]\n",
      "reward = 0 game_over = False\n",
      "[[' ' ' ' 'x' ' ' ' ']\n",
      " [' ' ' ' 'o' ' ' ' ']\n",
      " [' ' 'o' 'x' 'x' ' ']]\n",
      "reward = 0 game_over = False\n",
      "[[' ' ' ' 'x' ' ' ' ']\n",
      " [' ' ' ' 'o' 'x' ' ']\n",
      " [' ' 'o' 'x' 'x' ' ']]\n",
      "reward = 0 game_over = False\n",
      "[[' ' ' ' 'x' ' ' ' ']\n",
      " [' ' 'o' 'o' 'x' ' ']\n",
      " [' ' 'o' 'x' 'x' ' ']]\n",
      "reward = 0 game_over = False\n",
      "[[' ' ' ' 'x' 'x' ' ']\n",
      " [' ' 'o' 'o' 'x' ' ']\n",
      " [' ' 'o' 'x' 'x' ' ']]\n",
      "Player ' x ' has won the game!\n",
      "reward = -1 game_over = True\n"
     ]
    }
   ],
   "source": [
    "reward, game_over = env.act(action=3)\n",
    "print(\"reward =\", reward, \"game_over =\", game_over)\n",
    "env.change_turn()\n",
    "reward, game_over = env.act(action=1)\n",
    "print(\"reward =\", reward, \"game_over =\", game_over)\n",
    "env.change_turn()\n",
    "reward, game_over = env.act(action=3)\n",
    "print(\"reward =\", reward, \"game_over =\", game_over)\n",
    "env.change_turn()\n",
    "reward, game_over = env.act(action=1)\n",
    "print(\"reward =\", reward, \"game_over =\", game_over)\n",
    "env.change_turn()\n",
    "reward, game_over = env.act(action=3)\n",
    "print(\"reward =\", reward, \"game_over =\", game_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the `reward` returned by the `act()` method is the reward for player `'o'`.\n",
    "\n",
    "You can reset the game using the `reset()` method. This method cleans the grid and makes sure that the it is the `starting_player`'s turn as defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game has been reset.\n",
      "[[' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ']]\n",
      "[[' ' ' ' ' ' ' ' ' ']\n",
      " [' ' ' ' ' ' ' ' ' ']\n",
      " [' ' 'x' ' ' ' ' ' ']]\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "reward, game_over = env.act(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to modify existing or add new methods to the `Connect` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning\n",
    "\n",
    "**Your opponent is always the first player. Your agent is always the second player.**\n",
    "\n",
    "For your reference, the pseudo-code for Q-learning is reproduced below from the textbook (Reinforcement Learning, Sutton & Barto, 1998, Section 6.5).\n",
    "<img src=\"images/q_learning.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "Prepare a **learning curve** following the directions below. We refer to this as Plot 1.\n",
    "\n",
    "After $n$ steps of interaction with the environment, play $m$ games with the current policy of the agent (without modifying the policy). Think of this as interrupting the agent for a period of time to test how well it has learned so far. Your plot should show the total score obtained in these $m$ games as a function of $n, 2n, 3n, … kn$. The choices of $n$ and $k$ are up to you. They should be reasonable values that demonstrate the efficiency of the learning and how well the agent learns to play the game eventually. Use $m=10$. \n",
    "\n",
    "This plot should show the mean performance of `a` agents, not the performance of a single agent. Because of the stochasticity in the environment, you will obtain two different learning curves from two different agents even though they are using exactly the same algorithm. We suggest setting `a` to 20 or higher.\n",
    "\n",
    "Present a single mean learning curve with your choice of parameters $\\epsilon$ and $\\alpha$. The plot should also show (as a baseline) the mean performance of a random agent that does not learn but chooses actions uniformly randomly from among the legal actions. Label this line “Random Agent”. \n",
    "\n",
    "Please include this plot as a static figure in the appropriate cell below. That is, compute the learning curve in the lab or at home (this may take a couple of minutes depending on your implementation) and save the figure in the same directory as your notebook. Import this figure in the appropriate answer cell under (A). You can look at the source code of this markdown cell (double click on it!) to find out how to embed figures using html. Do **not** use drag & drop to include figures; we would not be able to see them! Make sure to include the locally stored images in your submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1431aa87b9e9019a4dbe6e696e0a9082",
     "grade": true,
     "grade_id": "cell-3ac2114f764e8410",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import Myconnect\n",
    "import numpy as np\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, env, epsilon=0.05, alpha=0.5, gamma=0.9):\n",
    "        self.env = env\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # construct Q table\n",
    "        self.Q = {}\n",
    "        \n",
    "        # Default last state action value \n",
    "        self.last_state_action = 0.0\n",
    "    \n",
    "    def update_q(self, state, best_state, action, reward):\n",
    "        \"\"\"update the Q table as moving\"\"\"\n",
    "        state = string_state(state)\n",
    "        best_state = string_state(best_state)\n",
    "        actions = self.env.available_actions\n",
    "        \n",
    "        # Gets q values of best state\n",
    "        best_state_q = self.q_table(best_state, actions)\n",
    "\n",
    "        if best_state_q:\n",
    "            max_q = max(best_state_q)\n",
    "        else:\n",
    "            max_q = 0.0\n",
    "            \n",
    "        # Update q table.\n",
    "        self.Q[(state, action)] = self.last_state_action + self.alpha * (reward + (self.gamma * max_q) - self.last_state_action)\n",
    "\n",
    "    \n",
    "    def q_table(self, state, actions):\n",
    "        q_table = []\n",
    "        for action in actions:\n",
    "            if self.Q.get((state,action)) == None:\n",
    "                self.Q[(state,action)] = 0.0\n",
    "                q_val = self.Q.get((state,action))\n",
    "                q_val = 0.0\n",
    "            else:\n",
    "                q_val = self.Q.get((state,action))\n",
    "                \n",
    "            q_table.append(q_val)\n",
    "            \n",
    "        return q_table\n",
    "\n",
    "    \n",
    "    def select_move(self, state):\n",
    "        \"\"\"select action from q table\"\"\"\n",
    "        state = string_state(state)\n",
    "        actions = self.env.available_actions\n",
    "        \n",
    "        #choose the action space\n",
    "        if np.random.uniform(0, 1) < self.epsilon: \n",
    "            action = random.choice(actions)\n",
    "            return action\n",
    "        \n",
    "        else: \n",
    "            #check the learned values\n",
    "            q_vals = self.q_table(state, actions)     \n",
    "            action = max(q_vals)\n",
    "            i = q_vals.index(action)\n",
    "        \n",
    "        self.last_state_action = self.Q[(state, actions[i])]\n",
    "        return actions[i]\n",
    "\n",
    "def string_state(state):\n",
    "    \"\"\"change the gird into a string\"\"\"   \n",
    "    stringed = \"\"\n",
    "    \n",
    "    for i in range(0,3):\n",
    "        for j in range(0,5):\n",
    "            stringed += state[i,j]\n",
    "            \n",
    "    return stringed    \n",
    "    \n",
    "def q_training(q_table, training=True, episodes=10):   \n",
    "    \"\"\"training for 10 episodes, and return stored reward\"\"\"\n",
    "    \n",
    "    temp_env = Myconnect.Connect(starting_player = 'x', verbose=False)\n",
    "    total_reward = 0\n",
    "\n",
    "    if training:\n",
    "        agent = Agent(temp_env, epsilon=0.0)\n",
    "        agent.Q = q_table\n",
    "    else: \n",
    "        agent = Agent(temp_env, epsilon=1.0)\n",
    "    \n",
    "    for i in range(episodes):\n",
    "        temp_env.reset()\n",
    "        temp_env.act(random.choice(temp_env.available_actions))\n",
    "        \n",
    "        done = False\n",
    "        \n",
    "        while not done and not temp_env.grid_is_full():\n",
    "            temp_env.change_turn()\n",
    "            state = np.copy(temp_env.grid)\n",
    "            action = agent.select_move(state)\n",
    "            #print(action)\n",
    "            temp_env.act(action)\n",
    "            total_reward = total_reward + reward(temp_env)\n",
    "        done = True\n",
    "    #print (total_reward)\n",
    "    return total_reward\n",
    "\n",
    "\n",
    "def reward(env):\n",
    "    reward = 0\n",
    "   \n",
    "    if env.grid_is_full():\n",
    "        return 0\n",
    "\n",
    "    if env.was_winning_move():\n",
    "            reward = 1\n",
    "    else:\n",
    "            #opponent's turn to run\n",
    "            env.change_turn()\n",
    "            env.act(random.choice(env.available_actions))\n",
    "            if env.was_winning_move():\n",
    "                    reward = -1\n",
    "    return reward\n",
    "\n",
    "def play(env, n, steps=50000, training=True):\n",
    "    \"\"\"Main function to start playing game\"\"\"\n",
    "    \n",
    "    q_agent = Agent(env)\n",
    "    \n",
    "    if not training:\n",
    "        q_agent.epsilon = 1.0\n",
    "    \n",
    "    # Collects reward every time.\n",
    "    reward_list = []\n",
    "\n",
    "    env.reset()\n",
    "    env.act(random.choice(env.available_actions))\n",
    "    \n",
    "    for i in range(1, steps):\n",
    "        if i % n == 0 or i == 1:  \n",
    "            temp_q_table = dict(q_agent.Q)\n",
    "            rewards = q_training(temp_q_table, training)\n",
    "            reward_list.append(rewards)\n",
    "            env.reset()\n",
    "            env.act(random.choice(env.available_actions))\n",
    "\n",
    "        initial_state = np.copy(env.grid)\n",
    "        env.change_turn()\n",
    "        action = q_agent.select_move(initial_state)\n",
    "        env.act(action)\n",
    "        new_state = np.copy(env.grid)\n",
    "        \n",
    "        if env.was_winning_move():\n",
    "            reward = 1\n",
    "            env.reset()\n",
    "            env.act(random.choice(env.available_actions))\n",
    "        elif env.grid_is_full():\n",
    "            reward = 0\n",
    "            env.reset()\n",
    "            env.act(random.choice(env.available_actions))\n",
    "        else:\n",
    "            #opponent's turn\n",
    "            env.change_turn()\n",
    "            env.act(random.choice(env.available_actions))\n",
    "            new_state = np.copy(env.grid)\n",
    "            if env.was_winning_move():\n",
    "                reward = -1\n",
    "                env.reset()\n",
    "                env.act(random.choice(env.available_actions))\n",
    "            elif env.grid_is_full():\n",
    "                reward = 0\n",
    "                env.reset()\n",
    "                env.act(random.choice(env.available_actions))\n",
    "            else:\n",
    "                reward = 0\n",
    "        #q_agent.epsilon = q_agent.epsilon - 1  \n",
    "        # if it is training, then update q table \n",
    "        if training:\n",
    "                q_agent.update_q(initial_state, new_state, action, reward)\n",
    "    \n",
    "    return reward_list\n",
    "\n",
    "#env = Myconnect.Connect(starting_player = 'x', verbose=False)\n",
    "#line = play(env, n=10, steps=100)\n",
    "#print (line)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-5-2f9ac8f3e5b3>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-2f9ac8f3e5b3>\"\u001b[1;36m, line \u001b[1;32m44\u001b[0m\n\u001b[1;33m    \"\"\"\"\u001b[0m\n\u001b[1;37m        \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "##cell to produce graph\n",
    "\n",
    "#comment out producing graph\n",
    "\"\"\"\"\n",
    "lines = []\n",
    "for i in range(0, 20):\n",
    "    env = Myconnect.Connect(starting_player = 'x', verbose=False)\n",
    "    line = play(env, n=10, steps=500)\n",
    "    lines.append(line)\n",
    "\n",
    "q_graph = []\n",
    "for j in range(0, len(line)):\n",
    "    avg = 0\n",
    "    for line in lines:\n",
    "        avg += line[j]\n",
    "    avg = avg / len(lines)\n",
    "    q_graph.append(avg) \n",
    "    \n",
    "    \n",
    "lines = []\n",
    "for i in range(0, 20):\n",
    "    env = Myconnect.Connect(starting_player = 'x', verbose=False)\n",
    "    line = play(env, n=10,steps=500, training=False)\n",
    "    lines.append(line)\n",
    "\n",
    "r_graph = []\n",
    "for j in range(0, len(line)):\n",
    "    avg = 0\n",
    "    for line in lines:\n",
    "        avg += line[j]\n",
    "    avg = avg / len(lines)\n",
    "    r_graph.append(avg)     \n",
    "\n",
    "    \n",
    "x = np.arange(1, len(q_graph) + 1)\n",
    "fig, (ax2) = plt.subplots(1,1)\n",
    "ax2.plot(x, q_graph,  label=\"Agent\")\n",
    "ax2.plot(x, r_graph,  label=\"Random Agent\")\n",
    "ax2.set_title(\" 30 agents, n=1000, m=10, games=50000\")\n",
    "ax2.set_xlabel('Games(in 1000)')\n",
    "ax2.set_ylabel('Average total reward' )\n",
    "\n",
    "plt.legend()\n",
    "plt.show()   \n",
    "\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "980d73fb62fae59d610abc96121f71bc",
     "grade": true,
     "grade_id": "cell-ce1405b859519f91",
     "locked": false,
     "points": 60,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "(A) [continued} Insert your static learning curve here (Plot 1).\n",
    "\n",
    "<img src=\"images/plot1.png\" style=\"width: 400px;\"/> \n",
    "\n",
    "(B) In 3 sentences or less, explain your conclusions from the plot above. How close does your (average) agent get to the best possible level of performance? How efficiently does your (average) agent learn? \n",
    "\n",
    "My agent got a score between 8 to 12, though it is higher than random agent.\n",
    "\n",
    "(C) In five sentences or less, explain the key aspects of your implementation. How many state-action pairs do you represent in your Q-table? Describe and justify your settings of $\\alpha$ and $\\epsilon$. Are there any things you tried out that are not in your final implementation?\n",
    "\n",
    "I used dictionary to store Q value\n",
    "alpha: i tried  from 0.1 to 1, then fixed it at 0.5, which is proved to be the optimal leanrning rate thourgh testing. \n",
    "epsilon: i kept epsilon at 0.05 as suggeted online.\n",
    "I tride to decay alpha very slowly after every episode in order to balance exploration and exloitation \n",
    "\n",
    "(D) In the cell below, make it possible for us to produce from scratch a learning curve similar to Plot 1 but for a single agent, for a $k$ value of your own choosing. You do not need to include the baseline for random play.  This code should run in less than 30 seconds (ours runs in 2 seconds). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e65915a61d304027e4fbd2e714c4beba",
     "grade": true,
     "grade_id": "cell-e0e01e05236aee45",
     "locked": false,
     "points": 40,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced in:   13.5625 seconds\n"
     ]
    }
   ],
   "source": [
    "### This cell should produce from scratch a plot showing a learning curve for a single agent.\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.process_time()\n",
    "env = Myconnect.Connect(verbose=False)\n",
    "line_graph = play(env, n=1000, steps=50000)\n",
    "\n",
    "x = np.arange(0, len(line_graph))\n",
    "plt.plot(x, line_graph)\n",
    "plt.title(\"Single Agent\")\n",
    "plt.xlabel(\"Games\")\n",
    "plt.ylabel(\"Average reward\")\n",
    "plt.show()\n",
    "print(\"Produced in:  \", time.process_time() - start_time, \"seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT: How to submit.\n",
    "\n",
    "If any of the following instructions is not clear, please ask your tutors well ahead of the submission deadline.\n",
    "\n",
    "### Before you submit\n",
    "- We will not be able to mark your coursework if it takes more than 1 minutes to execute your entire notebook. That is, comment out (but do not delete) the code that you used to produce Plot 1 (i.e., learning curve averaged across many agents). Do **not** comment out the code that you use to produce a learning curve for a single agent (Exercise D).\n",
    "- Restart the kernel (_Kernel $\\rightarrow$ Restart & Run All_) and make sure that you can run all cells from top to bottom without any errors.\n",
    "- Make sure that your code is written in Python 3 (and not in Python 2!). You can check the Python version of the current session in the top-right corner below the Python logo.\n",
    "\n",
    "### Submission file\n",
    "- Please upload to Moodle a .zip file (**not** `.rar`, `.7z`, or any other archive format) that contains the completed Jupyter notebook (`ai4_connect_three.ipynb`) as well as the pre-computed figure(s). \n",
    "- **If** you change the `connect.py` file or write your own version of the environment, include the corresponding file in your submission, but give it any other name than `connect.py`. If you do not change its name, it will be overwritten  and we won't be able to execute your code! Make sure that you import the correct module when you rename your file, for example, use `import myConnect` if your file is called `myConnect.py`.\n",
    "- Do not include any identifying information. Not in the code cells, not in the file names, nowhere! Marking is anonymous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
